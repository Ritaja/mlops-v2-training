{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Demo Notebook: Feathr Feature Store on Azure\n",
        "\n",
        "This notebook demonstrates how Feathr Feature Store can simplify and empower your model training and inference. You will learn:\n",
        "\n",
        "1. Define sharable features using Feathr API\n",
        "2. Create a training dataset via point-in-time feature join with Feathr API\n",
        "3. Materialize features to online store and then retrieve them with Feathr API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import Dependencies\n",
        "import glob\n",
        "import os\n",
        "import tempfile\n",
        "from datetime import datetime, timedelta\n",
        "from math import sqrt\n",
        "\n",
        "import pandas as pd\n",
        "import pandavro as pdx\n",
        "from feathr import FeathrClient\n",
        "from feathr import BOOLEAN, FLOAT, INT32, ValueType\n",
        "from feathr import Feature, DerivedFeature, FeatureAnchor\n",
        "from feathr import BackfillTime, MaterializationSettings\n",
        "from feathr import FeatureQuery, ObservationSettings\n",
        "from feathr import RedisSink\n",
        "from feathr import INPUT_CONTEXT, HdfsSource\n",
        "from feathr import WindowAggTransformation\n",
        "from feathr import TypedKey\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.keyvault.secrets import SecretClient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisite: Configure the required environment with Feathr Quick Start Template\n",
        "\n",
        "In the first step (Provision cloud resources), you should have provisioned all the required cloud resources. Run the code below to install Feathr, login to Azure to get the required credentials to access more cloud resources."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**REQUIRED STEP: Fill in the resource prefix when provisioning the resources**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "resource_prefix = \"rifeathr\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Login to Azure with a device code (You will see instructions in the output):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "**Permission**\n",
        "\n",
        "To proceed with the following steps, you may need additional permission: permission to access the keyvault, permission to access the Storage Blob as a Contributor and permission to submit jobs to Synapse cluster. Skip this step if you have already given yourself the access. Otherwise, run the following lines of command in the Cloud Shell before running the cell below.\n",
        "\n",
        "```\n",
        "userId=<email_id_of_account_requesting_access>\n",
        "resource_prefix=<resource_prefix>\n",
        "synapse_workspace_name=\"${resource_prefix}syws\"\n",
        "keyvault_name=\"${resource_prefix}kv\"\n",
        "objectId=$(az ad user show --id $userId --query id -o tsv)\n",
        "az keyvault update --name $keyvault_name --enable-rbac-authorization false\n",
        "az keyvault set-policy -n $keyvault_name --secret-permissions get list --object-id $objectId\n",
        "az role assignment create --assignee $userId --role \"Storage Blob Data Contributor\"\n",
        "az synapse role assignment create --workspace-name $synapse_workspace_name --role \"Synapse Contributor\" --assignee $userId\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get all the required credentials from Azure KeyVault"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get all the required credentials from Azure Key Vault\n",
        "key_vault_name=resource_prefix+\"kv\"\n",
        "synapse_workspace_url=resource_prefix+\"syws\"\n",
        "adls_account=resource_prefix+\"dls\"\n",
        "adls_fs_name=resource_prefix+\"fs\"\n",
        "purview_name=resource_prefix+\"purview\"\n",
        "key_vault_uri = f\"https://{key_vault_name}.vault.azure.net\"\n",
        "credential = DefaultAzureCredential(exclude_interactive_browser_credential=False)\n",
        "client = SecretClient(vault_url=key_vault_uri, credential=credential)\n",
        "secretName = \"FEATHR-ONLINE-STORE-CONN\"\n",
        "retrieved_secret = client.get_secret(secretName).value\n",
        "\n",
        "# Get redis credentials; This is to parse Redis connection string.\n",
        "redis_port=retrieved_secret.split(',')[0].split(\":\")[1]\n",
        "redis_host=retrieved_secret.split(',')[0].split(\":\")[0]\n",
        "redis_password=retrieved_secret.split(',')[1].split(\"password=\",1)[1]\n",
        "redis_ssl=retrieved_secret.split(',')[2].split(\"ssl=\",1)[1]\n",
        "\n",
        "# Set the resource link\n",
        "os.environ['spark_config__azure_synapse__dev_url'] = f'https://{synapse_workspace_url}.dev.azuresynapse.net'\n",
        "os.environ['spark_config__azure_synapse__pool_name'] = 'spark31'\n",
        "os.environ['spark_config__azure_synapse__workspace_dir'] = f'abfss://{adls_fs_name}@{adls_account}.dfs.core.windows.net/fraud/feathr_project'\n",
        "os.environ['online_store__redis__host'] = redis_host\n",
        "os.environ['online_store__redis__port'] = redis_port\n",
        "os.environ['online_store__redis__ssl_enabled'] = redis_ssl\n",
        "os.environ['REDIS_PASSWORD']=redis_password\n",
        "feathr_output_path = f'abfss://{adls_fs_name}@{adls_account}.dfs.core.windows.net/fraud/feathr_output'\n",
        "os.environ['FEATURE_REGISTRY__API_ENDPOINT']= f'https://{resource_prefix}webapp.azurewebsites.net/api/v1'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Define sharable features using Feathr API\n",
        "\n",
        "In this tutorial, we use Feathr Feature Store to help create a model that predicts users product rating. To make it simple, let's just predict users' rating for ONE product for an e-commerce website. (We have an [advanced demo](./product_recommendation_demo_advanced.ipynb) that predicts ratings for arbitrary products.)\n",
        "\n",
        "\n",
        "## Initialize Feathr Client\n",
        "\n",
        "Let's initialize a Feathr client first. The Feathr client provides all the APIs we need to interact with Feathr Feature Store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-11-25 18:57:04.310 | INFO     | feathr.utils._envvariableutil:get_environment_variable_with_default:51 - secrets__azure_key_vault__name not found in the config file.\n",
            "2022-11-25 18:57:04.409 | INFO     | feathr.utils._envvariableutil:get_environment_variable_with_default:51 - spark_config__azure_synapse__feathr_runtime_location not found in the config file.\n",
            "2022-11-25 18:57:07.170 | INFO     | feathr.utils._envvariableutil:get_environment_variable_with_default:51 - secrets__azure_key_vault__name not found in the config file.\n",
            "2022-11-25 18:57:07.181 | INFO     | feathr.client:__init__:176 - Feathr Client 0.9.0 initialized successfully\n"
          ]
        }
      ],
      "source": [
        "feathr_client = FeathrClient(config_path=\"feathr_config.yaml\", credential=credential)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understand the Raw Datasets\n",
        "We have 3 raw datasets to work with: one observation dataset(a.k.a. label dataset) and two raw datasets to generate features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>event_timestamp</th>\n",
              "      <th>product_rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    user_id  product_id event_timestamp  product_rating\n",
              "0         1           1      2021-04-01               4\n",
              "1         1           2      2021-04-01               4\n",
              "2         1           3      2021-04-01               4\n",
              "3         1           4      2021-04-01               4\n",
              "4         1           5      2021-04-01               4\n",
              "5         2           1      2021-04-01               5\n",
              "6         2           2      2021-04-01               5\n",
              "7         2           3      2021-04-01               5\n",
              "8         2           4      2021-04-01               5\n",
              "9         2           5      2021-04-01               5\n",
              "10        3           1      2021-04-01               5\n",
              "11        3           2      2021-04-01               5\n",
              "12        3           3      2021-04-01               5\n",
              "13        3           4      2021-04-01               5\n",
              "14        3           5      2021-04-01               5\n",
              "15        4           1      2021-04-01               1\n",
              "16        4           2      2021-04-01               1\n",
              "17        4           3      2021-04-01               1\n",
              "18        4           4      2021-04-01               1\n",
              "19        4           5      2021-04-01               1\n",
              "20        5           1      2021-04-01               5\n",
              "21        5           2      2021-04-01               5\n",
              "22        6           1      2021-04-01               2\n",
              "23        7           1      2021-04-01               5\n",
              "24        7           2      2021-04-01               5\n",
              "25        7           3      2021-04-01               5\n",
              "26        8           1      2021-04-01               2\n",
              "27        8           2      2021-04-01               2\n",
              "28        8           3      2021-04-01               2\n",
              "29        9           1      2021-04-01               5\n",
              "30        9           2      2021-04-01               5\n",
              "31        9           3      2021-04-01               5\n",
              "32        9           4      2021-04-01               5\n",
              "33       10           1      2021-04-01               3"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Observation dataset(a.k.a. label dataset)\n",
        "# Observation dataset usually comes with a event_timestamp to denote when the observation happened.\n",
        "# The label here is product_rating. Our model objective is to predict a user's rating for this product.\n",
        "import pandas as pd\n",
        "pd.read_csv(\"https://azurefeathrstorage.blob.core.windows.net/public/sample_data/product_recommendation_sample/user_observation_mock_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>gift_card_balance</th>\n",
              "      <th>number_of_credit_cards</th>\n",
              "      <th>state</th>\n",
              "      <th>tax_rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>CA</td>\n",
              "      <td>7.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>17</td>\n",
              "      <td>300</td>\n",
              "      <td>1</td>\n",
              "      <td>CA</td>\n",
              "      <td>7.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>WA</td>\n",
              "      <td>7.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>100</td>\n",
              "      <td>3</td>\n",
              "      <td>WA</td>\n",
              "      <td>7.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>PA</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>CA</td>\n",
              "      <td>7.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>22</td>\n",
              "      <td>200</td>\n",
              "      <td>1</td>\n",
              "      <td>WA</td>\n",
              "      <td>7.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>59</td>\n",
              "      <td>300</td>\n",
              "      <td>0</td>\n",
              "      <td>PA</td>\n",
              "      <td>8.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "      <td>WA</td>\n",
              "      <td>8.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>WA</td>\n",
              "      <td>7.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  gender  age  gift_card_balance  number_of_credit_cards state  \\\n",
              "0        1       1   22                100                       0    CA   \n",
              "1        2       2   17                300                       1    CA   \n",
              "2        3       1   40                  0                       2    WA   \n",
              "3        4       1   25                100                       3    WA   \n",
              "4        5       1   33                  0                       2    PA   \n",
              "5        6       2   19                  0                       2    CA   \n",
              "6        7       2   22                200                       1    WA   \n",
              "7        8       2   59                300                       0    PA   \n",
              "8        9       0   80                100                       1    WA   \n",
              "9       10       0   39                100                       0    WA   \n",
              "\n",
              "   tax_rate  \n",
              "0       7.5  \n",
              "1       7.5  \n",
              "2       7.5  \n",
              "3       7.5  \n",
              "4       0.0  \n",
              "5       7.5  \n",
              "6       7.5  \n",
              "7       8.5  \n",
              "8       8.5  \n",
              "9       7.5  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# User profile dataset\n",
        "# Used to generate user features\n",
        "import pandas as pd\n",
        "pd.read_csv(\"https://azurefeathrstorage.blob.core.windows.net/public/sample_data/product_recommendation_sample/user_profile_mock_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>purchase_date</th>\n",
              "      <th>purchase_amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2021-01-01</td>\n",
              "      <td>0.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2021-03-03</td>\n",
              "      <td>574.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2021-01-03</td>\n",
              "      <td>796.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>2021-01-04</td>\n",
              "      <td>342.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>2021-03-05</td>\n",
              "      <td>280.46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2</td>\n",
              "      <td>2021-01-06</td>\n",
              "      <td>664.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3</td>\n",
              "      <td>2021-01-07</td>\n",
              "      <td>359.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3</td>\n",
              "      <td>2021-01-08</td>\n",
              "      <td>357.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3</td>\n",
              "      <td>2021-01-09</td>\n",
              "      <td>845.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4</td>\n",
              "      <td>2021-01-10</td>\n",
              "      <td>103.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>4</td>\n",
              "      <td>2021-02-21</td>\n",
              "      <td>670.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>4</td>\n",
              "      <td>2021-02-12</td>\n",
              "      <td>698.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>5</td>\n",
              "      <td>2021-01-13</td>\n",
              "      <td>110.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>5</td>\n",
              "      <td>2021-01-14</td>\n",
              "      <td>931.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>5</td>\n",
              "      <td>2021-02-15</td>\n",
              "      <td>388.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>6</td>\n",
              "      <td>2021-01-16</td>\n",
              "      <td>822.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>6</td>\n",
              "      <td>2021-01-17</td>\n",
              "      <td>292.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>6</td>\n",
              "      <td>2021-01-18</td>\n",
              "      <td>524.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>7</td>\n",
              "      <td>2021-01-19</td>\n",
              "      <td>262.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>7</td>\n",
              "      <td>2021-03-20</td>\n",
              "      <td>715.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>7</td>\n",
              "      <td>2021-01-21</td>\n",
              "      <td>345.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>8</td>\n",
              "      <td>2021-01-22</td>\n",
              "      <td>379.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>8</td>\n",
              "      <td>2021-01-23</td>\n",
              "      <td>194.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>8</td>\n",
              "      <td>2021-01-24</td>\n",
              "      <td>862.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>9</td>\n",
              "      <td>2021-01-25</td>\n",
              "      <td>430.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>9</td>\n",
              "      <td>2021-01-26</td>\n",
              "      <td>398.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>9</td>\n",
              "      <td>2021-02-27</td>\n",
              "      <td>158.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>10</td>\n",
              "      <td>2021-01-28</td>\n",
              "      <td>550.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>10</td>\n",
              "      <td>2021-03-02</td>\n",
              "      <td>157.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>10</td>\n",
              "      <td>2021-03-03</td>\n",
              "      <td>528.43</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    user_id purchase_date  purchase_amount\n",
              "0         1    2021-01-01             0.33\n",
              "1         1    2021-03-03           574.35\n",
              "2         1    2021-01-03           796.07\n",
              "3         2    2021-01-04           342.15\n",
              "4         2    2021-03-05           280.46\n",
              "5         2    2021-01-06           664.18\n",
              "6         3    2021-01-07           359.02\n",
              "7         3    2021-01-08           357.12\n",
              "8         3    2021-01-09           845.40\n",
              "9         4    2021-01-10           103.92\n",
              "10        4    2021-02-21           670.12\n",
              "11        4    2021-02-12           698.65\n",
              "12        5    2021-01-13           110.52\n",
              "13        5    2021-01-14           931.72\n",
              "14        5    2021-02-15           388.14\n",
              "15        6    2021-01-16           822.96\n",
              "16        6    2021-01-17           292.39\n",
              "17        6    2021-01-18           524.76\n",
              "18        7    2021-01-19           262.00\n",
              "19        7    2021-03-20           715.94\n",
              "20        7    2021-01-21           345.70\n",
              "21        8    2021-01-22           379.00\n",
              "22        8    2021-01-23           194.96\n",
              "23        8    2021-01-24           862.33\n",
              "24        9    2021-01-25           430.41\n",
              "25        9    2021-01-26           398.72\n",
              "26        9    2021-02-27           158.52\n",
              "27       10    2021-01-28           550.01\n",
              "28       10    2021-03-02           157.88\n",
              "29       10    2021-03-03           528.43"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# User purchase history dataset.\n",
        "# Used to generate user features. This is activity type data, so we need to use aggregation to genearte features.\n",
        "import pandas as pd\n",
        "pd.read_csv(\"https://azurefeathrstorage.blob.core.windows.net/public/sample_data/product_recommendation_sample/user_purchase_history_mock_data.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " After a bit of data exploration, we want to create a training dataset like this:\n",
        "\n",
        " \n",
        "![Feature Flow](https://github.com/feathr-ai/feathr/blob/main/docs/images/product_recommendation.jpg?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What's a Feature in Feathr\n",
        "A feature is an individual measurable property or characteristic of a phenomenon which is sometimes time-sensitive. \n",
        "\n",
        "In Feathr, feature can be defined by the following characteristics:\n",
        "1. The typed key (a.k.a. entity id): identifies the subject of feature, e.g. a user id of 123, a product id of SKU234456.\n",
        "2. The feature name: the unique identifier of the feature, e.g. user_age, total_spending_in_30_days.\n",
        "3. The feature value: the actual value of that aspect at a particular time, e.g. the feature value of the person's age is 30 at year 2022.\n",
        "\n",
        "You can feel that this is defined from a feature consumer(a person who wants to use a feature) perspective. It only tells us what a feature is like. In later sections, you can see how a feature consumer can access the features in a very simple way.\n",
        "\n",
        "To define a feature as well as how it can be produced, additionally we need:\n",
        "1. Feature source: what source data that this feature is based on\n",
        "2. Transformation: what transformation is used to transform the source data into feature. Transformation can be optional when you just want to take a column out from the source data.\n",
        "\n",
        "(For more details on feature definition, please refer to the [Feathr Feature Definition Guide](https://github.com/feathr-ai/feathr/blob/main/docs/concepts/feature-definition.md))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define Sources Section with Preprocssing\n",
        "A [feature source](https://feathr.readthedocs.io/en/latest/#feathr.Source) defines where to find the source data and how to use the source data for the upcoming feature transformation. There are different types of feature sources that you can use. HdfsSource is the most commonly used one that can connect you to data lake, Snowflake database tables etc. It's simliar to database connector.\n",
        "\n",
        "To define HdfsSource, we need:\n",
        "1. `name`: It's used for you to recognize it. It has to be unique among all other feature source. Here we use `userProfileData`. \n",
        "2. `path`: It points to the location that we can find the source data.\n",
        "3. `preprocessing`(optional): If you want some preprocessing other than provided transformation, you can do it here. This preprocessing will be applied all the transformations of this source.\n",
        "4. `event_timestamp_column`(optioanl): there are `event_timestamp_column` and `timestamp_format` used for point-in-time join and we will cover them later.\n",
        "\n",
        "See [the python API documentation](https://feathr.readthedocs.io/en/latest/#feathr.HdfsSource) to get the details of each input fields. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession, DataFrame\n",
        "\n",
        "def feathr_udf_preprocessing(df: DataFrame) -> DataFrame:\n",
        "    from pyspark.sql.functions import col\n",
        "    df = df.withColumn(\"tax_rate_decimal\", col(\"tax_rate\")/100)\n",
        "    df.show(10)\n",
        "    return df\n",
        "\n",
        "batch_source = HdfsSource(name=\"userProfileData\",\n",
        "                          path=\"wasbs://public@azurefeathrstorage.blob.core.windows.net/sample_data/product_recommendation_sample/user_profile_mock_data.csv\",\n",
        "                          preprocessing=feathr_udf_preprocessing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define Features on Top of Data Sources\n",
        "To define features on top of the `HdfsSource`, we need to:\n",
        "1. specify the key of this feature: feature are like other data, they are keyed by some id. For example, user_id, product_id. You can also define compound keys.\n",
        "2. specify the name of the feature via `name` parameter and how to transform it from source data via `transform` parameter. Also some other metadata, like `feature_type`.\n",
        "3. group them together so we know it's from one `HdfsSource` via `FeatureAnchor`. Also give it a unique name via `name` parameter so we can recognize it.\n",
        "\n",
        "It's called FeatureAnchor since it's like this group of features are anchored to the source. There are other types of features that are computed on top of other features(a.k.a. derived feature which we will cover in next section)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "user_id = TypedKey(key_column=\"user_id\",\n",
        "                   key_column_type=ValueType.INT32,\n",
        "                   description=\"user id\",\n",
        "                   full_name=\"product_recommendation.user_id\")\n",
        "\n",
        "feature_user_age = Feature(name=\"feature_user_age\",\n",
        "                           key=user_id,\n",
        "                           feature_type=INT32, \n",
        "                           transform=\"age\")\n",
        "feature_user_tax_rate = Feature(name=\"feature_user_tax_rate\",\n",
        "                                key=user_id,\n",
        "                                feature_type=FLOAT,\n",
        "                                transform=\"tax_rate_decimal\")\n",
        "feature_user_gift_card_balance = Feature(name=\"feature_user_gift_card_balance\",\n",
        "                                    key=user_id,\n",
        "                                    feature_type=FLOAT,\n",
        "                                    transform=\"gift_card_balance\")\n",
        "feature_user_has_valid_credit_card = Feature(name=\"feature_user_has_valid_credit_card\",\n",
        "                                    key=user_id,\n",
        "                                    feature_type=BOOLEAN,\n",
        "                                    transform=\"number_of_credit_cards > 0\")\n",
        "                                    \n",
        "features = [\n",
        "    feature_user_age,\n",
        "    feature_user_tax_rate,\n",
        "    feature_user_gift_card_balance,\n",
        "    feature_user_has_valid_credit_card\n",
        "]\n",
        "\n",
        "request_anchor = FeatureAnchor(name=\"anchored_features\",\n",
        "                               source=batch_source,\n",
        "                               features=features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Window aggregation features\n",
        "\n",
        "Using [window aggregations](https://en.wikipedia.org/wiki/Window_function_%28SQL%29) can help us create more powerful features. A window aggregation feature compress large amount of information into one single feature value. Using our raw data as an example, we have the users' purchase history data that might be quite some rows, we want to create a window aggregation feature that represents their last 90 days of average purcahse amount.\n",
        "\n",
        "Feathr provides a nice API to help us create such window aggregation features.\n",
        "\n",
        "To create this window aggregation feature via Feathr, we just need to define the following parameters with `WindowAggTransformation` API:\n",
        "1. `agg_expr`: the field/column you want to aggregate. It can be a ANSI SQL expression. So we just write `cast_float(purchase_amount)`(the raw data might be in string form, let's cast_float).\n",
        "2. `agg_func`: the aggregation function you want. We want to use `AVG` here.\n",
        "3. `window`: the aggregation window size you want. Let's use `90d`. You can tune your windows to create different window aggregation features.\n",
        "\n",
        "For window aggregation functions, see the supported fields below:\n",
        "\n",
        "| Aggregation Type | Input Type | Description |\n",
        "| --- | --- | --- |\n",
        "|SUM, COUNT, MAX, MIN, AVG\t|Numeric|Applies the the numerical operation on the numeric inputs. |\n",
        "|MAX_POOLING, MIN_POOLING, AVG_POOLING\t| Numeric Vector | Applies the max/min/avg operation on a per entry bassis for a given a collection of numbers.|\n",
        "|LATEST| Any |Returns the latest not-null values from within the defined time window |\n",
        "\n",
        "(Note that the `agg_func` should be any of these.)\n",
        "\n",
        "After you have defined features and sources, bring them together to build an anchor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "purchase_history_data = HdfsSource(name=\"purchase_history_data\",\n",
        "                          path=\"wasbs://public@azurefeathrstorage.blob.core.windows.net/sample_data/product_recommendation_sample/user_purchase_history_mock_data.csv\",\n",
        "                          event_timestamp_column=\"purchase_date\",\n",
        "                          timestamp_format=\"yyyy-MM-dd\")\n",
        "                          \n",
        "agg_features = [Feature(name=\"feature_user_total_purchase_in_90days\",\n",
        "                        key=user_id,\n",
        "                        feature_type=FLOAT,\n",
        "                        transform=WindowAggTransformation(agg_expr=\"cast_float(purchase_amount)\",\n",
        "                                                          agg_func=\"AVG\",\n",
        "                                                          window=\"90d\"))\n",
        "                ]\n",
        "\n",
        "agg_anchor = FeatureAnchor(name=\"aggregationFeatures\",\n",
        "                           source=purchase_history_data,\n",
        "                           features=agg_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Derived Features Section\n",
        "Derived features are features that are computed from other Feathr features. They could be computed from anchored features, or other derived features.\n",
        "\n",
        "Typical usage includes feature cross(f1 * f2), or computing cosine similarity between two features.\n",
        "\n",
        "The syntax works in a similar way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_user_purchasing_power = DerivedFeature(name=\"feature_user_purchasing_power\",\n",
        "                                      key=user_id,\n",
        "                                      feature_type=FLOAT,\n",
        "                                      input_features=[feature_user_gift_card_balance, feature_user_has_valid_credit_card],\n",
        "                                      transform=\"feature_user_gift_card_balance + if_else(toBoolean(feature_user_has_valid_credit_card), 100, 0)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Build Features\n",
        "Lastly, we need to build those features so that it can be consumed later. Note that we have to build both the \"anchor\" and the \"derived\" features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "feathr_client.build_features(anchor_list=[agg_anchor, request_anchor], \n",
        "                      derived_feature_list=[feature_user_purchasing_power])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optional: A Special Type of Feature: Request Feature\n",
        "For advanced user cases, in some cases, features defined on top of request data(a.k.a. observation data) may have no entity key or timestamp.\n",
        "It is merely a function/transformation executing against request data at runtime.\n",
        "For example, the day of week of the request, which is calculated by converting the request UNIX timestamp.\n",
        "In this case, the `source` section should be `INPUT_CONTEXT` to indicate the source of those defined anchors.\n",
        "\n",
        "We won't cover the details it in this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create training data using point-in-time correct feature join\n",
        "\n",
        "A training dataset usually contains entity id column(s), multiple feature columns, event timestamp column and label/target column. \n",
        "\n",
        "To create a training dataset using Feathr, we need to provide a feature join settings to specify\n",
        "what features and how these features should be joined to the observation data. \n",
        "\n",
        "(To learn more on this topic, please refer to [Point-in-time Correctness](https://github.com/feathr-ai/feathr/blob/main/docs/concepts/point-in-time-join.md))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-10-23 21:02:19.881 | INFO     | feathr.spark_provider._synapse_submission:upload_or_get_cloud_path:66 - Uploading /tmp/tmpikx4ix11/feathr_pyspark_driver.py to cloud..\n",
            "2022-10-23 21:02:19.882 | INFO     | feathr.spark_provider._synapse_submission:upload_file:409 - Uploading file feathr_pyspark_driver.py\n",
            "2022-10-23 21:02:20.059 | INFO     | feathr.spark_provider._synapse_submission:upload_file:415 - /tmp/tmpikx4ix11/feathr_pyspark_driver.py is uploaded to location: abfss://mufyfeathrfs@mufyfeathrdls.dfs.core.windows.net/feathr_project/feathr_pyspark_driver.py\n",
            "2022-10-23 21:02:20.061 | INFO     | feathr.spark_provider._synapse_submission:upload_or_get_cloud_path:70 - /tmp/tmpikx4ix11/feathr_pyspark_driver.py is uploaded to location: abfss://mufyfeathrfs@mufyfeathrdls.dfs.core.windows.net/feathr_project/feathr_pyspark_driver.py\n",
            "2022-10-23 21:02:20.076 | INFO     | feathr.spark_provider._synapse_submission:upload_or_get_cloud_path:66 - Uploading /tmp/tmpikx4ix11/feature_join_conf/feature_join.conf to cloud..\n",
            "2022-10-23 21:02:20.077 | INFO     | feathr.spark_provider._synapse_submission:upload_file:409 - Uploading file feature_join.conf\n",
            "2022-10-23 21:02:20.270 | INFO     | feathr.spark_provider._synapse_submission:upload_file:415 - /tmp/tmpikx4ix11/feature_join_conf/feature_join.conf is uploaded to location: abfss://mufyfeathrfs@mufyfeathrdls.dfs.core.windows.net/feathr_project/feature_join.conf\n",
            "2022-10-23 21:02:20.271 | INFO     | feathr.spark_provider._synapse_submission:upload_or_get_cloud_path:70 - /tmp/tmpikx4ix11/feature_join_conf/feature_join.conf is uploaded to location: abfss://mufyfeathrfs@mufyfeathrdls.dfs.core.windows.net/feathr_project/feature_join.conf\n",
            "2022-10-23 21:02:20.272 | INFO     | feathr.spark_provider._synapse_submission:upload_or_get_cloud_path:66 - Uploading /tmp/tmpikx4ix11/feature_conf/ to cloud..\n",
            "2022-10-23 21:02:20.273 | INFO     | feathr.spark_provider._synapse_submission:upload_file_to_workdir:397 - Uploading folder /tmp/tmpikx4ix11/feature_conf/\n",
            "2022-10-23 21:02:20.274 | INFO     | feathr.spark_provider._synapse_submission:upload_file:409 - Uploading file auto_generated_request_features.conf\n",
            "2022-10-23 21:02:20.520 | INFO     | feathr.spark_provider._synapse_submission:upload_file:415 - /tmp/tmpikx4ix11/feature_conf/auto_generated_request_features.conf is uploaded to location: abfss://mufyfeathrfs@mufyfeathrdls.dfs.core.windows.net/feathr_project/auto_generated_request_features.conf\n",
            "2022-10-23 21:02:20.522 | INFO     | feathr.spark_provider._synapse_submission:upload_file:409 - Uploading file auto_generated_anchored_features.conf\n",
            "2022-10-23 21:02:20.704 | INFO     | feathr.spark_provider._synapse_submission:upload_file:415 - /tmp/tmpikx4ix11/feature_conf/auto_generated_anchored_features.conf is uploaded to location: abfss://mufyfeathrfs@mufyfeathrdls.dfs.core.windows.net/feathr_project/auto_generated_anchored_features.conf\n",
            "2022-10-23 21:02:20.706 | INFO     | feathr.spark_provider._synapse_submission:upload_file:409 - Uploading file auto_generated_derived_features.conf\n",
            "2022-10-23 21:02:20.860 | INFO     | feathr.spark_provider._synapse_submission:upload_file:415 - /tmp/tmpikx4ix11/feature_conf/auto_generated_derived_features.conf is uploaded to location: abfss://mufyfeathrfs@mufyfeathrdls.dfs.core.windows.net/feathr_project/auto_generated_derived_features.conf\n",
            "2022-10-23 21:02:20.862 | INFO     | feathr.spark_provider._synapse_submission:upload_or_get_cloud_path:70 - /tmp/tmpikx4ix11/feature_conf/ is uploaded to location: abfss://mufyfeathrfs@mufyfeathrdls.dfs.core.windows.net/feathr_project/auto_generated_request_features.conf,abfss://mufyfeathrfs@mufyfeathrdls.dfs.core.windows.net/feathr_project/auto_generated_anchored_features.conf,abfss://mufyfeathrfs@mufyfeathrdls.dfs.core.windows.net/feathr_project/auto_generated_derived_features.conf\n",
            "2022-10-23 21:02:20.862 | INFO     | feathr.utils._envvariableutil:get_environment_variable:82 - ADLS_ACCOUNT is not set in the environment variables.\n",
            "2022-10-23 21:02:20.863 | INFO     | feathr.utils._envvariableutil:get_environment_variable:82 - ADLS_KEY is not set in the environment variables.\n",
            "2022-10-23 21:02:20.864 | INFO     | feathr.utils._envvariableutil:get_environment_variable:82 - BLOB_ACCOUNT is not set in the environment variables.\n",
            "2022-10-23 21:02:20.864 | INFO     | feathr.utils._envvariableutil:get_environment_variable:82 - BLOB_KEY is not set in the environment variables.\n",
            "2022-10-23 21:02:21.614 | INFO     | feathr.spark_provider._synapse_submission:submit_feathr_job:166 - See submitted job here: https://web.azuresynapse.net/en-us/monitoring/sparkapplication\n",
            "2022-10-23 21:02:21.807 | INFO     | feathr.spark_provider._synapse_submission:wait_for_completion:176 - Current Spark job status: not_started\n",
            "2022-10-23 21:02:52.089 | INFO     | feathr.spark_provider._synapse_submission:wait_for_completion:176 - Current Spark job status: starting\n",
            "2022-10-23 21:03:22.311 | INFO     | feathr.spark_provider._synapse_submission:wait_for_completion:176 - Current Spark job status: running\n",
            "2022-10-23 21:03:52.585 | INFO     | feathr.spark_provider._synapse_submission:wait_for_completion:176 - Current Spark job status: running\n",
            "2022-10-23 21:04:22.847 | INFO     | feathr.spark_provider._synapse_submission:wait_for_completion:176 - Current Spark job status: running\n",
            "2022-10-23 21:04:53.057 | INFO     | feathr.spark_provider._synapse_submission:wait_for_completion:176 - Current Spark job status: running\n",
            "2022-10-23 21:05:23.247 | INFO     | feathr.spark_provider._synapse_submission:wait_for_completion:176 - Current Spark job status: running\n",
            "2022-10-23 21:05:53.450 | INFO     | feathr.spark_provider._synapse_submission:wait_for_completion:176 - Current Spark job status: running\n",
            "2022-10-23 21:06:23.726 | INFO     | feathr.spark_provider._synapse_submission:wait_for_completion:176 - Current Spark job status: success\n"
          ]
        }
      ],
      "source": [
        "# Synapse and Databricks have different output path format\n",
        "if feathr_client.spark_runtime == 'databricks':\n",
        "    output_path = 'dbfs:/feathrazure_test.avro'\n",
        "else:\n",
        "    output_path = feathr_output_path\n",
        "\n",
        "# Features that we want to request\n",
        "feature_query = FeatureQuery(feature_list=[\"feature_user_age\", \n",
        "                                           \"feature_user_tax_rate\", \n",
        "                                           \"feature_user_gift_card_balance\", \n",
        "                                           \"feature_user_has_valid_credit_card\", \n",
        "                                           \"feature_user_total_purchase_in_90days\",\n",
        "                                           \"feature_user_purchasing_power\"], \n",
        "                             key=user_id)\n",
        "settings = ObservationSettings(\n",
        "    observation_path=\"wasbs://public@azurefeathrstorage.blob.core.windows.net/sample_data/product_recommendation_sample/user_observation_mock_data.csv\",\n",
        "    event_timestamp_column=\"event_timestamp\",\n",
        "    timestamp_format=\"yyyy-MM-dd\")\n",
        "feathr_client.get_offline_features(observation_settings=settings,\n",
        "                            feature_query=feature_query,\n",
        "                            output_path=output_path)\n",
        "feathr_client.wait_job_to_finish(timeout_sec=50000000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download the result and show the result\n",
        "\n",
        "Let's use the helper function `get_result_df` to download the result and view it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-10-23 21:07:53.653 | INFO     | feathr.spark_provider._synapse_submission:wait_for_completion:176 - Current Spark job status: success\n",
            "2022-10-23 21:07:53.820 | INFO     | feathr.spark_provider._synapse_submission:download_file:427 - Beginning reading of results from abfss://mufyfeathrfs@mufyfeathrdls.dfs.core.windows.net/feathr_output\n",
            "Downloading result files: 100%|| 12/12 [00:00<00:00, 15.95it/s]\n",
            "2022-10-23 21:07:54.744 | INFO     | feathr.spark_provider._synapse_submission:download_file:456 - Finish downloading files from abfss://mufyfeathrfs@mufyfeathrdls.dfs.core.windows.net/feathr_output to /tmp/tmp_0art4d6.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>event_timestamp</th>\n",
              "      <th>product_rating</th>\n",
              "      <th>feature_user_total_purchase_in_90days</th>\n",
              "      <th>feature_user_gift_card_balance</th>\n",
              "      <th>feature_user_has_valid_credit_card</th>\n",
              "      <th>feature_user_tax_rate</th>\n",
              "      <th>feature_user_age</th>\n",
              "      <th>feature_user_purchasing_power</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>5</td>\n",
              "      <td>329.216675</td>\n",
              "      <td>100.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0.085</td>\n",
              "      <td>80</td>\n",
              "      <td>200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>5</td>\n",
              "      <td>329.216675</td>\n",
              "      <td>100.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0.085</td>\n",
              "      <td>80</td>\n",
              "      <td>200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>5</td>\n",
              "      <td>329.216675</td>\n",
              "      <td>100.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0.085</td>\n",
              "      <td>80</td>\n",
              "      <td>200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>5</td>\n",
              "      <td>329.216675</td>\n",
              "      <td>100.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0.085</td>\n",
              "      <td>80</td>\n",
              "      <td>200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>4</td>\n",
              "      <td>456.916656</td>\n",
              "      <td>100.0</td>\n",
              "      <td>False</td>\n",
              "      <td>0.075</td>\n",
              "      <td>22</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>4</td>\n",
              "      <td>456.916656</td>\n",
              "      <td>100.0</td>\n",
              "      <td>False</td>\n",
              "      <td>0.075</td>\n",
              "      <td>22</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>4</td>\n",
              "      <td>456.916656</td>\n",
              "      <td>100.0</td>\n",
              "      <td>False</td>\n",
              "      <td>0.075</td>\n",
              "      <td>22</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>4</td>\n",
              "      <td>456.916656</td>\n",
              "      <td>100.0</td>\n",
              "      <td>False</td>\n",
              "      <td>0.075</td>\n",
              "      <td>22</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>4</td>\n",
              "      <td>456.916656</td>\n",
              "      <td>100.0</td>\n",
              "      <td>False</td>\n",
              "      <td>0.075</td>\n",
              "      <td>22</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>2</td>\n",
              "      <td>546.703369</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0.075</td>\n",
              "      <td>19</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>3</td>\n",
              "      <td>412.106689</td>\n",
              "      <td>100.0</td>\n",
              "      <td>False</td>\n",
              "      <td>0.075</td>\n",
              "      <td>39</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>1</td>\n",
              "      <td>490.896637</td>\n",
              "      <td>100.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0.075</td>\n",
              "      <td>25</td>\n",
              "      <td>200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>1</td>\n",
              "      <td>490.896637</td>\n",
              "      <td>100.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0.075</td>\n",
              "      <td>25</td>\n",
              "      <td>200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>1</td>\n",
              "      <td>490.896637</td>\n",
              "      <td>100.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0.075</td>\n",
              "      <td>25</td>\n",
              "      <td>200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>1</td>\n",
              "      <td>490.896637</td>\n",
              "      <td>100.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0.075</td>\n",
              "      <td>25</td>\n",
              "      <td>200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>1</td>\n",
              "      <td>490.896637</td>\n",
              "      <td>100.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0.075</td>\n",
              "      <td>25</td>\n",
              "      <td>200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>5</td>\n",
              "      <td>520.513367</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0.075</td>\n",
              "      <td>40</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>5</td>\n",
              "      <td>520.513367</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0.075</td>\n",
              "      <td>40</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>5</td>\n",
              "      <td>520.513367</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0.075</td>\n",
              "      <td>40</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>5</td>\n",
              "      <td>520.513367</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0.075</td>\n",
              "      <td>40</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>5</td>\n",
              "      <td>520.513367</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0.075</td>\n",
              "      <td>40</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>5</td>\n",
              "      <td>476.793335</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0.000</td>\n",
              "      <td>33</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>5</td>\n",
              "      <td>476.793335</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0.000</td>\n",
              "      <td>33</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>5</td>\n",
              "      <td>428.929962</td>\n",
              "      <td>300.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17</td>\n",
              "      <td>400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>5</td>\n",
              "      <td>428.929962</td>\n",
              "      <td>300.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17</td>\n",
              "      <td>400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>5</td>\n",
              "      <td>428.929962</td>\n",
              "      <td>300.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17</td>\n",
              "      <td>400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>5</td>\n",
              "      <td>428.929962</td>\n",
              "      <td>300.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17</td>\n",
              "      <td>400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>5</td>\n",
              "      <td>428.929962</td>\n",
              "      <td>300.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17</td>\n",
              "      <td>400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>2</td>\n",
              "      <td>478.763336</td>\n",
              "      <td>300.0</td>\n",
              "      <td>False</td>\n",
              "      <td>0.085</td>\n",
              "      <td>59</td>\n",
              "      <td>300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>2</td>\n",
              "      <td>478.763336</td>\n",
              "      <td>300.0</td>\n",
              "      <td>False</td>\n",
              "      <td>0.085</td>\n",
              "      <td>59</td>\n",
              "      <td>300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>2</td>\n",
              "      <td>478.763336</td>\n",
              "      <td>300.0</td>\n",
              "      <td>False</td>\n",
              "      <td>0.085</td>\n",
              "      <td>59</td>\n",
              "      <td>300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>5</td>\n",
              "      <td>441.213348</td>\n",
              "      <td>200.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0.075</td>\n",
              "      <td>22</td>\n",
              "      <td>300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>5</td>\n",
              "      <td>441.213348</td>\n",
              "      <td>200.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0.075</td>\n",
              "      <td>22</td>\n",
              "      <td>300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>5</td>\n",
              "      <td>441.213348</td>\n",
              "      <td>200.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0.075</td>\n",
              "      <td>22</td>\n",
              "      <td>300.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  user_id product_id event_timestamp product_rating  \\\n",
              "0       9          1      2021-04-01              5   \n",
              "1       9          2      2021-04-01              5   \n",
              "2       9          3      2021-04-01              5   \n",
              "3       9          4      2021-04-01              5   \n",
              "0       1          1      2021-04-01              4   \n",
              "1       1          2      2021-04-01              4   \n",
              "2       1          3      2021-04-01              4   \n",
              "3       1          4      2021-04-01              4   \n",
              "4       1          5      2021-04-01              4   \n",
              "0       6          1      2021-04-01              2   \n",
              "0      10          1      2021-04-01              3   \n",
              "0       4          1      2021-04-01              1   \n",
              "1       4          2      2021-04-01              1   \n",
              "2       4          3      2021-04-01              1   \n",
              "3       4          4      2021-04-01              1   \n",
              "4       4          5      2021-04-01              1   \n",
              "0       3          1      2021-04-01              5   \n",
              "1       3          2      2021-04-01              5   \n",
              "2       3          3      2021-04-01              5   \n",
              "3       3          4      2021-04-01              5   \n",
              "4       3          5      2021-04-01              5   \n",
              "0       5          1      2021-04-01              5   \n",
              "1       5          2      2021-04-01              5   \n",
              "0       2          1      2021-04-01              5   \n",
              "1       2          2      2021-04-01              5   \n",
              "2       2          3      2021-04-01              5   \n",
              "3       2          4      2021-04-01              5   \n",
              "4       2          5      2021-04-01              5   \n",
              "0       8          1      2021-04-01              2   \n",
              "1       8          2      2021-04-01              2   \n",
              "2       8          3      2021-04-01              2   \n",
              "0       7          1      2021-04-01              5   \n",
              "1       7          2      2021-04-01              5   \n",
              "2       7          3      2021-04-01              5   \n",
              "\n",
              "   feature_user_total_purchase_in_90days  feature_user_gift_card_balance  \\\n",
              "0                             329.216675                           100.0   \n",
              "1                             329.216675                           100.0   \n",
              "2                             329.216675                           100.0   \n",
              "3                             329.216675                           100.0   \n",
              "0                             456.916656                           100.0   \n",
              "1                             456.916656                           100.0   \n",
              "2                             456.916656                           100.0   \n",
              "3                             456.916656                           100.0   \n",
              "4                             456.916656                           100.0   \n",
              "0                             546.703369                             0.0   \n",
              "0                             412.106689                           100.0   \n",
              "0                             490.896637                           100.0   \n",
              "1                             490.896637                           100.0   \n",
              "2                             490.896637                           100.0   \n",
              "3                             490.896637                           100.0   \n",
              "4                             490.896637                           100.0   \n",
              "0                             520.513367                             0.0   \n",
              "1                             520.513367                             0.0   \n",
              "2                             520.513367                             0.0   \n",
              "3                             520.513367                             0.0   \n",
              "4                             520.513367                             0.0   \n",
              "0                             476.793335                             0.0   \n",
              "1                             476.793335                             0.0   \n",
              "0                             428.929962                           300.0   \n",
              "1                             428.929962                           300.0   \n",
              "2                             428.929962                           300.0   \n",
              "3                             428.929962                           300.0   \n",
              "4                             428.929962                           300.0   \n",
              "0                             478.763336                           300.0   \n",
              "1                             478.763336                           300.0   \n",
              "2                             478.763336                           300.0   \n",
              "0                             441.213348                           200.0   \n",
              "1                             441.213348                           200.0   \n",
              "2                             441.213348                           200.0   \n",
              "\n",
              "   feature_user_has_valid_credit_card  feature_user_tax_rate  \\\n",
              "0                                True                  0.085   \n",
              "1                                True                  0.085   \n",
              "2                                True                  0.085   \n",
              "3                                True                  0.085   \n",
              "0                               False                  0.075   \n",
              "1                               False                  0.075   \n",
              "2                               False                  0.075   \n",
              "3                               False                  0.075   \n",
              "4                               False                  0.075   \n",
              "0                                True                  0.075   \n",
              "0                               False                  0.075   \n",
              "0                                True                  0.075   \n",
              "1                                True                  0.075   \n",
              "2                                True                  0.075   \n",
              "3                                True                  0.075   \n",
              "4                                True                  0.075   \n",
              "0                                True                  0.075   \n",
              "1                                True                  0.075   \n",
              "2                                True                  0.075   \n",
              "3                                True                  0.075   \n",
              "4                                True                  0.075   \n",
              "0                                True                  0.000   \n",
              "1                                True                  0.000   \n",
              "0                                True                  0.075   \n",
              "1                                True                  0.075   \n",
              "2                                True                  0.075   \n",
              "3                                True                  0.075   \n",
              "4                                True                  0.075   \n",
              "0                               False                  0.085   \n",
              "1                               False                  0.085   \n",
              "2                               False                  0.085   \n",
              "0                                True                  0.075   \n",
              "1                                True                  0.075   \n",
              "2                                True                  0.075   \n",
              "\n",
              "   feature_user_age  feature_user_purchasing_power  \n",
              "0                80                          200.0  \n",
              "1                80                          200.0  \n",
              "2                80                          200.0  \n",
              "3                80                          200.0  \n",
              "0                22                          100.0  \n",
              "1                22                          100.0  \n",
              "2                22                          100.0  \n",
              "3                22                          100.0  \n",
              "4                22                          100.0  \n",
              "0                19                          100.0  \n",
              "0                39                          100.0  \n",
              "0                25                          200.0  \n",
              "1                25                          200.0  \n",
              "2                25                          200.0  \n",
              "3                25                          200.0  \n",
              "4                25                          200.0  \n",
              "0                40                          100.0  \n",
              "1                40                          100.0  \n",
              "2                40                          100.0  \n",
              "3                40                          100.0  \n",
              "4                40                          100.0  \n",
              "0                33                          100.0  \n",
              "1                33                          100.0  \n",
              "0                17                          400.0  \n",
              "1                17                          400.0  \n",
              "2                17                          400.0  \n",
              "3                17                          400.0  \n",
              "4                17                          400.0  \n",
              "0                59                          300.0  \n",
              "1                59                          300.0  \n",
              "2                59                          300.0  \n",
              "0                22                          300.0  \n",
              "1                22                          300.0  \n",
              "2                22                          300.0  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_result_df(client: FeathrClient) -> pd.DataFrame:\n",
        "    \"\"\"Download the job result dataset from cloud as a Pandas dataframe.\"\"\"\n",
        "    res_url = client.get_job_result_uri(block=True, timeout_sec=600)\n",
        "    tmp_dir = tempfile.TemporaryDirectory()\n",
        "    client.feathr_spark_launcher.download_result(result_path=res_url, local_folder=tmp_dir.name)\n",
        "    dataframe_list = []\n",
        "    # assuming the result are in avro format\n",
        "    for file in glob.glob(os.path.join(tmp_dir.name, '*.avro')):\n",
        "        dataframe_list.append(pdx.read_avro(file))\n",
        "    vertical_concat_df = pd.concat(dataframe_list, axis=0)\n",
        "    tmp_dir.cleanup()\n",
        "    return vertical_concat_df\n",
        "\n",
        "df_res = get_result_df(feathr_client)\n",
        "\n",
        "df_res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train a machine learning model\n",
        "After getting all the features, let's train a machine learning model with the converted feature by Feathr:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model MAPE:\n",
            "8.230754469954842e-06\n",
            "\n",
            "Model Accuracy:\n",
            "0.99999176924553\n"
          ]
        }
      ],
      "source": [
        "# drop non-feature columns\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "final_df = df_res\n",
        "final_df.drop([\"event_timestamp\"], axis=1, inplace=True, errors='ignore')\n",
        "final_df.fillna(0, inplace=True)\n",
        "final_df['product_rating'] = final_df['product_rating'].astype(\"float64\")\n",
        "\n",
        "train_x, test_x, train_y, test_y = train_test_split(final_df.drop([\"product_rating\", \"user_id\", \"product_id\"], axis=1),\n",
        "                                                    final_df[\"product_rating\"],\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=42)\n",
        "\n",
        "\n",
        "model = GradientBoostingRegressor()\n",
        "model.fit(train_x, train_y)\n",
        "\n",
        "y_predict = model.predict(test_x)\n",
        "\n",
        "y_actual = test_y.values.flatten().tolist()\n",
        "rmse = sqrt(mean_squared_error(y_actual, y_predict))\n",
        "\n",
        "sum_actuals = sum_errors = 0\n",
        "\n",
        "for actual_val, predict_val in zip(y_actual, y_predict):\n",
        "    abs_error = actual_val - predict_val\n",
        "    if abs_error < 0:\n",
        "        abs_error = abs_error * -1\n",
        "\n",
        "    sum_errors = sum_errors + abs_error\n",
        "    sum_actuals = sum_actuals + actual_val\n",
        "\n",
        "mean_abs_percent_error = sum_errors / sum_actuals\n",
        "print(\"Model MAPE:\")\n",
        "print(mean_abs_percent_error)\n",
        "print()\n",
        "print(\"Model Accuracy:\")\n",
        "print(1 - mean_abs_percent_error)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "   feature_user_total_purchase_in_90days  feature_user_gift_card_balance  \\\n",
            "1                             490.896637                           100.0   \n",
            "1                             441.213348                           200.0   \n",
            "0                             546.703369                             0.0   \n",
            "0                             329.216675                           100.0   \n",
            "\n",
            "   feature_user_has_valid_credit_card  feature_user_tax_rate  \\\n",
            "1                                True                  0.075   \n",
            "1                                True                  0.075   \n",
            "0                                True                  0.075   \n",
            "0                                True                  0.085   \n",
            "\n",
            "   feature_user_age  feature_user_purchasing_power  \n",
            "1                25                          200.0  \n",
            "1                22                          300.0  \n",
            "0                19                          100.0  \n",
            "0                80                          200.0  \n"
          ]
        }
      ],
      "source": [
        "train_x.shape\n",
        "\n",
        "print (type (train_x))\n",
        "\n",
        "print (train_x.head(4))\n",
        "\n",
        "#train_x.columns\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Materialize feature value into offline/online storage\n",
        "\n",
        "In the previous section, we demonstrated how Feathr can compute feature value to generate training dataset from feature definition on-they-fly.\n",
        "\n",
        "Now let's talk about how we can use the trained models. We can use the trained models for offline inference as well as online inference. In both cases, we need features to be feed into the models. For offline inference, you can compute and get the features on-demand; or you can store the computed features to some offline database for later offline inference.\n",
        "\n",
        "For online inference, we can use Feathr to compute and store the features in the online database. Then use it for online inference when the request comes.\n",
        "\n",
        "![img](../images/online_inference.jpg)\n",
        "\n",
        "\n",
        "In this section, we will focus on materialize features to online store. For materialization to offline store, you can check out our [user guide](https://github.com/feathr-ai/feathr/blob/main/docs/concepts/materializing-features.md#materializing-features-to-offline-store).\n",
        "\n",
        "We can push the computed features to the online store like below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-10-23 21:18:26.594 | INFO     | feathr.spark_provider._synapse_submission:upload_or_get_cloud_path:66 - Uploading /tmp/tmpikx4ix11/feathr_pyspark_driver.py to cloud..\n",
            "2022-10-23 21:18:26.595 | INFO     | feathr.spark_provider._synapse_submission:upload_file:409 - Uploading file feathr_pyspark_driver.py\n",
            "2022-10-23 21:18:27.119 | INFO     | feathr.spark_provider._synapse_submission:upload_file:415 - /tmp/tmpikx4ix11/feathr_pyspark_driver.py is uploaded to location: abfss://mufyfeathrfs@mufyfeathrdls.dfs.core.windows.net/feathr_project/feathr_pyspark_driver.py\n",
            "2022-10-23 21:18:27.120 | INFO     | feathr.spark_provider._synapse_submission:upload_or_get_cloud_path:70 - /tmp/tmpikx4ix11/feathr_pyspark_driver.py is uploaded to location: abfss://mufyfeathrfs@mufyfeathrdls.dfs.core.windows.net/feathr_project/feathr_pyspark_driver.py\n",
            "2022-10-23 21:18:27.120 | INFO     | feathr.utils._envvariableutil:get_environment_variable:82 - KAFKA_SASL_JAAS_CONFIG is not set in the environment variables.\n",
            "2022-10-23 21:18:27.121 | INFO     | feathr.spark_provider._synapse_submission:upload_or_get_cloud_path:66 - Uploading /tmp/tmpikx4ix11/feature_gen_conf/auto_gen_config_1589932800.0.conf to cloud..\n",
            "2022-10-23 21:18:27.122 | INFO     | feathr.spark_provider._synapse_submission:upload_file:409 - Uploading file auto_gen_config_1589932800.0.conf\n",
            "2022-10-23 21:18:27.440 | INFO     | feathr.spark_provider._synapse_submission:upload_file:415 - /tmp/tmpikx4ix11/feature_gen_conf/auto_gen_config_1589932800.0.conf is uploaded to location: abfss://mufyfeathrfs@mufyfeathrdls.dfs.core.windows.net/feathr_project/auto_gen_config_1589932800.0.conf\n",
            "2022-10-23 21:18:27.441 | INFO     | feathr.spark_provider._synapse_submission:upload_or_get_cloud_path:70 - /tmp/tmpikx4ix11/feature_gen_conf/auto_gen_config_1589932800.0.conf is uploaded to location: abfss://mufyfeathrfs@mufyfeathrdls.dfs.core.windows.net/feathr_project/auto_gen_config_1589932800.0.conf\n",
            "2022-10-23 21:18:27.441 | INFO     | feathr.spark_provider._synapse_submission:upload_or_get_cloud_path:66 - Uploading /tmp/tmpikx4ix11/feature_conf/ to cloud..\n",
            "2022-10-23 21:18:27.442 | INFO     | feathr.spark_provider._synapse_submission:upload_file_to_workdir:397 - Uploading folder /tmp/tmpikx4ix11/feature_conf/\n",
            "2022-10-23 21:18:27.443 | INFO     | feathr.spark_provider._synapse_submission:upload_file:409 - Uploading file auto_generated_request_features.conf\n",
            "2022-10-23 21:18:27.682 | INFO     | feathr.spark_provider._synapse_submission:upload_file:415 - /tmp/tmpikx4ix11/feature_conf/auto_generated_request_features.conf is uploaded to location: abfss://mufyfeathrfs@mufyfeathrdls.dfs.core.windows.net/feathr_project/auto_generated_request_features.conf\n",
            "2022-10-23 21:18:27.683 | INFO     | feathr.spark_provider._synapse_submission:upload_file:409 - Uploading file auto_generated_anchored_features.conf\n",
            "2022-10-23 21:18:27.924 | INFO     | feathr.spark_provider._synapse_submission:upload_file:415 - /tmp/tmpikx4ix11/feature_conf/auto_generated_anchored_features.conf is uploaded to location: abfss://mufyfeathrfs@mufyfeathrdls.dfs.core.windows.net/feathr_project/auto_generated_anchored_features.conf\n",
            "2022-10-23 21:18:27.925 | INFO     | feathr.spark_provider._synapse_submission:upload_file:409 - Uploading file auto_generated_derived_features.conf\n",
            "2022-10-23 21:18:28.152 | INFO     | feathr.spark_provider._synapse_submission:upload_file:415 - /tmp/tmpikx4ix11/feature_conf/auto_generated_derived_features.conf is uploaded to location: abfss://mufyfeathrfs@mufyfeathrdls.dfs.core.windows.net/feathr_project/auto_generated_derived_features.conf\n",
            "2022-10-23 21:18:28.154 | INFO     | feathr.spark_provider._synapse_submission:upload_or_get_cloud_path:70 - /tmp/tmpikx4ix11/feature_conf/ is uploaded to location: abfss://mufyfeathrfs@mufyfeathrdls.dfs.core.windows.net/feathr_project/auto_generated_request_features.conf,abfss://mufyfeathrfs@mufyfeathrdls.dfs.core.windows.net/feathr_project/auto_generated_anchored_features.conf,abfss://mufyfeathrfs@mufyfeathrdls.dfs.core.windows.net/feathr_project/auto_generated_derived_features.conf\n",
            "2022-10-23 21:18:28.154 | INFO     | feathr.utils._envvariableutil:get_environment_variable:82 - ADLS_ACCOUNT is not set in the environment variables.\n",
            "2022-10-23 21:18:28.155 | INFO     | feathr.utils._envvariableutil:get_environment_variable:82 - ADLS_KEY is not set in the environment variables.\n",
            "2022-10-23 21:18:28.155 | INFO     | feathr.utils._envvariableutil:get_environment_variable:82 - BLOB_ACCOUNT is not set in the environment variables.\n",
            "2022-10-23 21:18:28.156 | INFO     | feathr.utils._envvariableutil:get_environment_variable:82 - BLOB_KEY is not set in the environment variables.\n",
            "2022-10-23 21:18:28.160 | INFO     | feathr.utils._envvariableutil:get_environment_variable_with_default:51 - monitoring__database__sql__url not found in the config file.\n",
            "2022-10-23 21:18:28.163 | INFO     | feathr.utils._envvariableutil:get_environment_variable_with_default:51 - monitoring__database__sql__user not found in the config file.\n",
            "2022-10-23 21:18:28.164 | INFO     | feathr.utils._envvariableutil:get_environment_variable:82 - MONITORING_DATABASE_SQL_PASSWORD is not set in the environment variables.\n",
            "2022-10-23 21:18:28.804 | INFO     | feathr.spark_provider._synapse_submission:submit_feathr_job:166 - See submitted job here: https://web.azuresynapse.net/en-us/monitoring/sparkapplication\n",
            "2022-10-23 21:18:28.982 | INFO     | feathr.spark_provider._synapse_submission:wait_for_completion:176 - Current Spark job status: not_started\n",
            "2022-10-23 21:18:59.205 | INFO     | feathr.spark_provider._synapse_submission:wait_for_completion:176 - Current Spark job status: starting\n",
            "2022-10-23 21:19:29.407 | INFO     | feathr.spark_provider._synapse_submission:wait_for_completion:176 - Current Spark job status: running\n",
            "2022-10-23 21:19:59.618 | INFO     | feathr.spark_provider._synapse_submission:wait_for_completion:176 - Current Spark job status: running\n",
            "2022-10-23 21:20:29.876 | INFO     | feathr.spark_provider._synapse_submission:wait_for_completion:176 - Current Spark job status: running\n",
            "2022-10-23 21:21:00.117 | INFO     | feathr.spark_provider._synapse_submission:wait_for_completion:176 - Current Spark job status: running\n",
            "2022-10-23 21:21:30.339 | INFO     | feathr.spark_provider._synapse_submission:wait_for_completion:176 - Current Spark job status: success\n"
          ]
        }
      ],
      "source": [
        "backfill_time = BackfillTime(start=datetime(2020, 5, 20), \n",
        "                             end=datetime(2020, 5, 20), \n",
        "                             step=timedelta(days=1))\n",
        "redisSink = RedisSink(table_name=\"productRecommendationDemoFeature\")\n",
        "settings = MaterializationSettings(name=\"productRecommendationFeatureSetting\",\n",
        "                                   backfill_time=backfill_time,\n",
        "                                   sinks=[redisSink],\n",
        "                                   feature_names=['feature_user_total_purchase_in_90days',\n",
        "       'feature_user_gift_card_balance', 'feature_user_has_valid_credit_card',\n",
        "       'feature_user_tax_rate', 'feature_user_age',\n",
        "       'feature_user_purchasing_power'])\n",
        "\n",
        "\n",
        "feathr_client.materialize_features(settings)\n",
        "feathr_client.wait_job_to_finish(timeout_sec=500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fetch feature value from online store\n",
        "We can then get the features from the online store (Redis) via the client's `get_online_features` or `multi_get_online_features` API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'list'>\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "single_online_inference_data = feathr_client.get_online_features('productRecommendationDemoFeature', \n",
        "                           '2', ['feature_user_total_purchase_in_90days',\n",
        "       'feature_user_gift_card_balance', 'feature_user_has_valid_credit_card',\n",
        "       'feature_user_tax_rate', 'feature_user_age',\n",
        "       'feature_user_purchasing_power'])\n",
        "\n",
        "\n",
        "print (type(single_online_inference_data))\n",
        "\n",
        "single_online_inference_data_np  = np.array(single_online_inference_data)\n",
        "\n",
        "single_online_inference_data_np= single_online_inference_data_np.reshape (-1, 6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2, 6)"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "multiple_online_inference_data = feathr_client.multi_get_online_features('productRecommendationDemoFeature', \n",
        "                                 ['1', '2'], \n",
        "                                 ['feature_user_total_purchase_in_90days',\n",
        "       'feature_user_gift_card_balance', 'feature_user_has_valid_credit_card',\n",
        "       'feature_user_tax_rate', 'feature_user_age',\n",
        "       'feature_user_purchasing_power'])\n",
        "\n",
        "df = pd.DataFrame(multiple_online_inference_data)\n",
        "df = df.values.reshape (-1, 6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/feathr-env2/lib/python3.10/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([4.99996655, 4.99996655])"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict (df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Registering and Fetching features\n",
        "\n",
        "We can also register the features with an Apache Atlas compatible service, such as Azure Purview, and share the registered features across teams:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Failed to call registry API, status is 400, error is <html>\r\n<head><title>400 Request Header Or Cookie Too Large</title></head>\r\n<body>\r\n<center><h1>400 Bad Request</h1></center>\r\n<center>Request Header Or Cookie Too Large</center>\r\n<hr><center>nginx/1.18.0</center>\r\n</body>\r\n</html>\r\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m feathr_client\u001b[39m.\u001b[39;49mregister_features()\n",
            "File \u001b[1;32mc:\\Users\\risengupta\\miniconda3\\envs\\datascience-env\\lib\\site-packages\\feathr\\client.py:201\u001b[0m, in \u001b[0;36mFeathrClient.register_features\u001b[1;34m(self, from_context)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39manchor_list\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mdir\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mderived_feature_list\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mdir\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mregistry\u001b[39m.\u001b[39msave_to_feature_config_from_context(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39manchor_list, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mderived_feature_list, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlocal_workspace_dir)\n\u001b[1;32m--> 201\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mregistry\u001b[39m.\u001b[39;49mregister_features(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlocal_workspace_dir, from_context\u001b[39m=\u001b[39;49mfrom_context, anchor_list\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49manchor_list, derived_feature_list\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mderived_feature_list)\n\u001b[0;32m    202\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPlease call FeathrClient.build_features() first in order to register features\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\risengupta\\miniconda3\\envs\\datascience-env\\lib\\site-packages\\feathr\\registry\\_feathr_registry_client.py:105\u001b[0m, in \u001b[0;36m_FeatureRegistry.register_features\u001b[1;34m(self, workspace_path, from_context, anchor_list, derived_feature_list)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    102\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCurrently Feathr only supports registering features from context (i.e. you must call FeathrClient.build_features() before calling this function).\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    104\u001b[0m \u001b[39m# Before starting, create the project\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproject_id \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_project()\n\u001b[0;32m    107\u001b[0m \u001b[39mfor\u001b[39;00m anchor \u001b[39min\u001b[39;00m anchor_list:\n\u001b[0;32m    108\u001b[0m     source \u001b[39m=\u001b[39m anchor\u001b[39m.\u001b[39msource\n",
            "File \u001b[1;32mc:\\Users\\risengupta\\miniconda3\\envs\\datascience-env\\lib\\site-packages\\feathr\\registry\\_feathr_registry_client.py:151\u001b[0m, in \u001b[0;36m_FeatureRegistry._create_project\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_create_project\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m UUID:\n\u001b[1;32m--> 151\u001b[0m     r \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m/projects\u001b[39;49m\u001b[39m\"\u001b[39;49m, {\u001b[39m\"\u001b[39;49m\u001b[39mname\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mproject_name})\n\u001b[0;32m    152\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproject_id \u001b[39m=\u001b[39m UUID(r[\u001b[39m\"\u001b[39m\u001b[39mguid\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    153\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproject_id\n",
            "File \u001b[1;32mc:\\Users\\risengupta\\miniconda3\\envs\\datascience-env\\lib\\site-packages\\feathr\\registry\\_feathr_registry_client.py:194\u001b[0m, in \u001b[0;36m_FeatureRegistry._post\u001b[1;34m(self, path, body)\u001b[0m\n\u001b[0;32m    192\u001b[0m logging\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mPATH: \u001b[39m\u001b[39m\"\u001b[39m, path)\n\u001b[0;32m    193\u001b[0m logging\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mBODY: \u001b[39m\u001b[39m\"\u001b[39m, json\u001b[39m.\u001b[39mdumps(body, indent\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m))\n\u001b[1;32m--> 194\u001b[0m \u001b[39mreturn\u001b[39;00m check(requests\u001b[39m.\u001b[39;49mpost(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendpoint\u001b[39m}\u001b[39;49;00m\u001b[39m{\u001b[39;49;00mpath\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m, headers\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_auth_header(), json\u001b[39m=\u001b[39;49mbody))\u001b[39m.\u001b[39mjson()\n",
            "File \u001b[1;32mc:\\Users\\risengupta\\miniconda3\\envs\\datascience-env\\lib\\site-packages\\feathr\\registry\\_feathr_registry_client.py:381\u001b[0m, in \u001b[0;36mcheck\u001b[1;34m(r)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck\u001b[39m(r):\n\u001b[0;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m r\u001b[39m.\u001b[39mok:\n\u001b[1;32m--> 381\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    382\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to call registry API, status is \u001b[39m\u001b[39m{\u001b[39;00mr\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m, error is \u001b[39m\u001b[39m{\u001b[39;00mr\u001b[39m.\u001b[39mtext\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    383\u001b[0m     \u001b[39mreturn\u001b[39;00m r\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Failed to call registry API, status is 400, error is <html>\r\n<head><title>400 Request Header Or Cookie Too Large</title></head>\r\n<body>\r\n<center><h1>400 Bad Request</h1></center>\r\n<center>Request Header Or Cookie Too Large</center>\r\n<hr><center>nginx/1.18.0</center>\r\n</body>\r\n</html>\r\n"
          ]
        }
      ],
      "source": [
        "feathr_client.register_features()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'name': 'feature_user_purchasing_power',\n",
              "  'id': '26963c3f-25cd-48ec-bf76-c1dcb3662107',\n",
              "  'qualifiedName': 'feathr_getting_started_demo2__feature_user_purchasing_power'},\n",
              " {'name': 'feature_user_gift_card_balance',\n",
              "  'id': '508b60db-c7f9-4154-9fa1-31478d1366ef',\n",
              "  'qualifiedName': 'feathr_getting_started_demo2__anchored_features__feature_user_gift_card_balance'},\n",
              " {'name': 'feature_user_tax_rate',\n",
              "  'id': '942de3ae-b26e-4748-a96c-c4a7fc10f4d0',\n",
              "  'qualifiedName': 'feathr_getting_started_demo2__anchored_features__feature_user_tax_rate'},\n",
              " {'name': 'feature_user_total_purchase_in_90days',\n",
              "  'id': 'c892d722-9295-4273-995d-ab4dcc375503',\n",
              "  'qualifiedName': 'feathr_getting_started_demo2__aggregationFeatures__feature_user_total_purchase_in_90days'},\n",
              " {'name': 'feature_user_has_valid_credit_card',\n",
              "  'id': 'ebbb6abf-bb1b-4784-b819-92b01bbfa374',\n",
              "  'qualifiedName': 'feathr_getting_started_demo2__anchored_features__feature_user_has_valid_credit_card'},\n",
              " {'name': 'feature_user_age',\n",
              "  'id': 'f3688adc-9020-4758-aefc-7910af79fca7',\n",
              "  'qualifiedName': 'feathr_getting_started_demo2__anchored_features__feature_user_age'}]"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feathr_client.list_registered_features(project_name=\"feathr_getting_started_demo2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "myenv"
    },
    "kernelspec": {
      "display_name": "Python 3.10.8 ('datascience-env')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "76eb2aec7b8806467e5d9c0e966809eb3a31c63dba131d7a65edc5945fc5d1fa"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
